---
title: AI-based Autonomous Rover
layout: default
parent: Posts
nav_order: 2
---

## KAIST EE405A AI-based Autonomous Rover  
### 지능기반 자율주행 로버 개발


![robot](../images/robot.jpg)  


Main Task: Avoid Obstacles and Remove Landmines


**Set Up**  
Ubuntu 20.04 LTS, ROS1 Noetic,  
NVIDIA Jetson Orin Nano (Main PC), Hiwonder ArmPI Pro (Robot), Intel Realsense (Sensor)  


**Overall Architecture**  
![overall architecture](../images/overall_architecture.png)  


**1. Localization**  

- ORB SLAM  
  **SLAM**(Simultaneous Localization and Mapping)은 Robot이 주행하면서 자신의 위치를 추정하고 스스로 지도를 생성하는 기술이다. LiDAR 기반과 Visual SLAM 방식이 있는데, 본 프로젝트에서는 Visual SLAM을 사용하였다. LiDAR 기반은 레이저 빛이 물체에 반사되어 들어오는 시간을 계산하여 주변 환경을 인식하고, Visual SLAM은 카메라로 Feature Points를 찍어서 그 점들의 위치 변화를 통해 지도를 만든다. IMU 데이터를 기반으로 시작 위치로부터 현재 위치를 계산하고 칼만 필터로 잡음을 제거하여 정확한 위치를 파악한다.

- Tag Localization  
  Map과 Tag 사이의 Transformation은 이미 알고 있기 때문에 Robot이 카메라로 Tag를 인식하면 ORB SLAM으로부터 얻은 local position을 map coordinate으로 **Transform** 할 수 있다.

![Frame Transformation](../images/TF.png) 
<div align="center">
    <img src="../images/TF.png">
</div>
<div class="caption">
  Frame Transformation
</div> 


**2. Object Detection**  
- YOLO v5
- Target Position Estimation

**3. Mission Planner**
- Node-link Generator
- Global Path Planner
- Mission Planner

**4. Motion Planner**
- Manipulator Mission Planner
- Local Path Planner

**5. Control**
- Manipulator Controller
- Mobile Robot Controller


