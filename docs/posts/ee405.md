---
title: AI-based Autonomous Rover
layout: default
parent: Posts
nav_order: 2
---

## KAIST EE405A AI-based Autonomous Rover  
### 지능기반 자율주행 로버 개발


![robot](../images/robot.jpg)  


Main Task: Avoid Obstacles and Remove Landmines


**Set Up**  
Ubuntu 20.04 LTS  
ROS1 Noetic  
NVIDIA Jetson Orin Nano (Main PC)  
Hiwonder ArmPI Pro (Robot)  
Intel Realsense (Sensor)  

**Overall Architecture**  
![overall architecture](../images/overall_architecture.png)  
<img src="../images/overall_architecture.png" width="500">


1. Localization  

**Transformation** between fixed global frame of a map and dynamic local body frame of the robot.

![Frame Transformation](../images/TF.png) 





- ORB SLAM : Get robot's odometry through Visual SLAM (Simultaneous Localization and Mapping)

  **SLAM**은 Robot이 주행하면서 자신의 위치를 추정하고 스스로 지도를 생성하는 기술이다. LiDAR 기반과 Visual SLAM 방식이 있는데, 본 프로젝트에서는 Visual SLAM을 사용하였다. LiDAR 기반은 레이저 빛이 물체에 반사되어 들어오는 시간을 계산하여 주변 환경을 인식하고, Visual SLAM은 카메라로 Feature Points를 찍어서 그 점들의 위치 변화를 통해 지도를 만든다. IMU 데이터를 기반으로 시작 위치로부터 현재 위치를 계산하고 칼만 필터로 잡음을 제거하여 정확한 위치를 파악한다.

- Tag Localization : Align odometry with a global map using AprilTag

  Robot이 카메라로 Tag를 인식하면 ORB SLAM으로부터 얻은 local position을 map coordinate으로 Transform 해준다.


  


2. Object Detection  
- YOLO v5
- Target Position Estimation

3. Mission Planner
- Node-link Generator
- Global Path Planner
- Mission Planner

4. Motion Planner
- Manipulator Mission Planner
- Local Path Planner

5. Control
- Manipulator Controller
- Mobile Robot Controller


